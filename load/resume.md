# Nishanth Sety

**Summary**

Seasoned Data Engineer with over 4 years of experience in designing and optimizing data pipelines using Big Data technologies like Hadoop, Spark, Kafka, and Hive. Skilled in cloud-native data engineering on AWS and Azure, with expertise in Azure Data Factory, Databricks, Snowflake, and Redis. Strong background in ETL development, data lake/warehouse architectures, and data governance across the full data lifecycle. Proficient in building complex data workflows with Apache Airflow and migrating databases to Snowflake. Experienced in agile methodologies and CI/CD using tools like Git, Jenkins, Docker, and Kubernetes..

## Experience
**Data Engineer** at HCA, Nashville, TN (Jan 2023 - Present)

- Designed and automated data ingestion pipelines using Spark, Sqoop, and Oozie, optimizing RDBMS-to-Azure Data Lake workflows.
- Developed data integration pipelines connecting MongoDB with Power BI, enabling seamless real-time data visualization and reporting.
- Created and managed data models in Azure Synapse, supporting enterprise-level analytics with automated ETL workflows.
- Developed large ETL models combining multiple sources using Azure Data Factory and Databricks for incremental data loads.

**Data Engineer** at Mastercard, St. Louis, MO (Jul 2022 - Dec 2022)

- Built scalable data pipelines utilizing AWS services (EMR, EC2, S3, RDS, Redshift) for large-scale data processing and analytics.
- Enhanced ETL performance using Spark’s in-memory processing, improving the speed of processing large datasets stored in S3.
- Optimized SQL queries for data transformation, ensuring faster data processing and improved system reliability.
- Integrated diverse data sources and adhered to data quality standards, following Agile methodologies for efficient project delivery.

**Data Engineer** at HTC GLobal, India (Jul 2019 - Jun 2021)

- Developed healthcare analytics systems using R, Hadoop, and MongoDB, ensuring compliance with data governance protocols.
- Built ETL pipelines with Spark, SQL, and Redshift, processing large healthcare datasets to derive valuable business insights.
- Implemented CI/CD pipelines using Jenkins and Terraform, automating AWS deployments and reducing operational downtime.
- Processed and migrated data using AWS EMR and Glue, streamlining complex healthcare data integration.

## Education
**Master's Degree in Computer Science** - University of Central Missouri (2021-2022)

## Skills
Hadoop, Spark, Kafka, Azure Data Factory, Power BI, Snowflake
